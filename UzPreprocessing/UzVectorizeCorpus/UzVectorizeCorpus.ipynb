{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87647cf6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc7acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b82c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SHAPE = 8\n",
    "SEQUENCE_SHAPE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3698529",
   "metadata": {},
   "source": [
    "# Vectorize Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5399d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cut_dict_values(input_dict: dict, k: int) -> dict:\n",
    "    lambda_ = lambda value: value[:k]\n",
    "    dict_ = dict(zip(input_dict, map(lambda_, input_dict.values())))\n",
    "    return dict_\n",
    "\n",
    "def _concat_columns(dataframe: pd.DataFrame) -> np.ndarray:\n",
    "    if dataframe.shape[0] == 0:\n",
    "        return np.array([], dtype=object)\n",
    "    array = dataframe.iloc[0].values\n",
    "    result = [array]\n",
    "    for i in range(1, dataframe.shape[0]):\n",
    "        curr_array = dataframe.iloc[i].values\n",
    "        result = np.append(result, [curr_array], axis=0)\n",
    "    return result\n",
    "\n",
    "def create_ngrams(sentence: list, sequence_shape: int) -> pd.Series:\n",
    "    if sequence_shape > len(sentence):\n",
    "        return pd.Series(dtype='object')\n",
    "    n_words = len(sentence) - sequence_shape + 1\n",
    "    n_sentence = sentence[:n_words]\n",
    "    ngrams = pd.Series(dtype='object')\n",
    "    for i in range(len(n_sentence)):\n",
    "        ngrams = ngrams.append(pd.Series([sentence[i:i + sequence_shape]]))\n",
    "    ngrams.reset_index(drop=True, inplace=True)\n",
    "    return ngrams\n",
    "\n",
    "def vectorize_text(text: str,\n",
    "                   word_vector_dict: dict,\n",
    "                   vector_shape: int,\n",
    "                   sequence_shape: int) -> np.ndarray:\n",
    "    word_vector_dict = _cut_dict_values(word_vector_dict, vector_shape)\n",
    "    sentence = text.split()\n",
    "    ngrams = create_ngrams(sentence, sequence_shape)\n",
    "    dataframe_ngrams = ngrams.apply(lambda ngram: pd.Series(ngram))\n",
    "    dataframe_vectors = dataframe_ngrams.apply(lambda ngram: ngram.map(word_vector_dict))\n",
    "    result_dataframe = _concat_columns(dataframe_vectors)\n",
    "    return result_dataframe\n",
    "\n",
    "def vectorize_corpus(corpus_array: np.ndarray,\n",
    "                     word_vector_dict: dict,\n",
    "                     vector_shape: int,\n",
    "                     sequence_shape: int) -> np.ndarray:\n",
    "    result = list()\n",
    "    for text_index in tqdm(range(len(corpus_array))):\n",
    "        vectorized_text = vectorize_text(corpus_array[text_index], word_vector_dict,\n",
    "                                         vector_shape, sequence_shape)\n",
    "        result.append(vectorized_text)\n",
    "    return np.array(result, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e31323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"UzCleanCorpus.csv\")\n",
    "word_list = np.load(\"WORD_LIST.npy\")\n",
    "word_vectors = np.load(\"U.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b215ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 9583/9583 [1:07:05<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "word_vector_dict = dict(zip(word_list, word_vectors))\n",
    "vectorized_corpus = vectorize_corpus(corpus['clean_text'].values,\n",
    "                                     word_vector_dict,\n",
    "                                     VECTOR_SHAPE,\n",
    "                                     SEQUENCE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16480be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(\"UzVectorizedCorpus\", vectorized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fff026",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c5bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = np.load(\"UzVectorizedCorpus.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e172c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9583"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c058ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
