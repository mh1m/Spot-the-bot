{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvKLls3Ol-vr"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5203,
     "status": "ok",
     "timestamp": 1641572055118,
     "user": {
      "displayName": "Максим Селезнев",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01035662716647446064"
     },
     "user_tz": -180
    },
    "id": "CznNTk3VmOLT",
    "outputId": "bce71080-c496-49d9-eb3d-0f89fc4adde4"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from devon.devon import FSMStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_by_length(text: str, min_len: int = 2, max_len: int = 30) -> str:\n",
    "    word_list = text.split()\n",
    "    result_list = []\n",
    "    for word in word_list:\n",
    "        if len(word) >= min_len and len(word) <= max_len:\n",
    "            result_list.append(word)\n",
    "    result_text = ' '.join(result_list)\n",
    "    return result_text\n",
    "\n",
    "def clean_text(text: str, stop_words: list) -> str:\n",
    "    result_text_list = []\n",
    "    splited_text = re.split(r\"[^A-Za-z 'ʻʼ-]+\", text)\n",
    "    for sentence in splited_text:\n",
    "        word_list = nltk.tokenize.WhitespaceTokenizer().tokenize(sentence)\n",
    "        for word in word_list:\n",
    "            if len(word) == 0 or word == '-':\n",
    "                continue\n",
    "            if word[0] == '-':\n",
    "                word = word[1:]\n",
    "            try:\n",
    "                if word[-1] == '-':\n",
    "                    word = word[:-1]\n",
    "            except IndexError:\n",
    "                pass\n",
    "            lower_word = word.lower()\n",
    "            stem_word = FSMStemmer().stem(words=lower_word)[0]\n",
    "            if stem_word not in stop_words:\n",
    "                result_text_list.append(stem_word)\n",
    "    result_text = ' '.join(result_text_list)\n",
    "    result_text = _clean_by_length(result_text)\n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"UzWikiTexts.csv\")\n",
    "stop_words = json.load(open(\"UzStopWords.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = lambda text: clean_text(text, stop_words)\n",
    "dataframe['clean_text'] = dataframe.loc[:, 'sentence'].apply(lambda_)\n",
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_uuid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2508e29b-6b60-42c5-bc8e-577f3a124cf1</td>\n",
       "      <td>ShoʻrvaShoʻrva — suyuq ovqat turi.</td>\n",
       "      <td>shoʻrvashoʻrva suyuq ovqat tur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508e29b-6b60-42c5-bc8e-577f3a124cf1</td>\n",
       "      <td>Tayyorlash usuliga koʻra, shoʻrvaning qovurma ...</td>\n",
       "      <td>tayyorlash usul koʻra shoʻrva qovurma shoʻrva ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2508e29b-6b60-42c5-bc8e-577f3a124cf1</td>\n",
       "      <td>Goʻsht boʻlaklarga boʻlinib, yogʻ bilan birga ...</td>\n",
       "      <td>goʻsht boʻlak boʻlinib yogʻ qizarguncha soʻngr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2508e29b-6b60-42c5-bc8e-577f3a124cf1</td>\n",
       "      <td>Suv qaynab chiqquncha qozonga tuz, bir dona qi...</td>\n",
       "      <td>suv qaynab chiqquncha qozon tuz dona qizil qal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2508e29b-6b60-42c5-bc8e-577f3a124cf1</td>\n",
       "      <td>Shoʻrva qaynab chiqqach, olovi pasaytirilib, y...</td>\n",
       "      <td>shoʻrva qaynab chiqqach olov pasaytirilib soat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157634</th>\n",
       "      <td>665ef546-82b2-4ac8-ab4d-07667cf39271</td>\n",
       "      <td>Aholi zichligi – har kvadrat kilometrga 25,4 n...</td>\n",
       "      <td>ahol zichlig kvadrat kilometr kish geografiya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157635</th>\n",
       "      <td>665ef546-82b2-4ac8-ab4d-07667cf39271</td>\n",
       "      <td>Shundan 3,70 km2 quruqlik.</td>\n",
       "      <td>shun quruqlik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157636</th>\n",
       "      <td>665ef546-82b2-4ac8-ab4d-07667cf39271</td>\n",
       "      <td>Dengiz sathidan oʻrtacha 290 m balandlikda joy...</td>\n",
       "      <td>de sath oʻrtacha balandlik joylashgan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157637</th>\n",
       "      <td>de26d018-dbc2-4bc4-a55b-2567f60747bf</td>\n",
       "      <td>Amenia, North Dakota</td>\n",
       "      <td>amenia north dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157638</th>\n",
       "      <td>24d7fe0b-b5c2-4522-b8a1-9b037c414e35</td>\n",
       "      <td>Amenia, Shimoliy Dakota</td>\n",
       "      <td>amenia shimoliy dakota</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1157639 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 article_uuid  \\\n",
       "0        2508e29b-6b60-42c5-bc8e-577f3a124cf1   \n",
       "1        2508e29b-6b60-42c5-bc8e-577f3a124cf1   \n",
       "2        2508e29b-6b60-42c5-bc8e-577f3a124cf1   \n",
       "3        2508e29b-6b60-42c5-bc8e-577f3a124cf1   \n",
       "4        2508e29b-6b60-42c5-bc8e-577f3a124cf1   \n",
       "...                                       ...   \n",
       "1157634  665ef546-82b2-4ac8-ab4d-07667cf39271   \n",
       "1157635  665ef546-82b2-4ac8-ab4d-07667cf39271   \n",
       "1157636  665ef546-82b2-4ac8-ab4d-07667cf39271   \n",
       "1157637  de26d018-dbc2-4bc4-a55b-2567f60747bf   \n",
       "1157638  24d7fe0b-b5c2-4522-b8a1-9b037c414e35   \n",
       "\n",
       "                                                  sentence  \\\n",
       "0                       ShoʻrvaShoʻrva — suyuq ovqat turi.   \n",
       "1        Tayyorlash usuliga koʻra, shoʻrvaning qovurma ...   \n",
       "2        Goʻsht boʻlaklarga boʻlinib, yogʻ bilan birga ...   \n",
       "3        Suv qaynab chiqquncha qozonga tuz, bir dona qi...   \n",
       "4        Shoʻrva qaynab chiqqach, olovi pasaytirilib, y...   \n",
       "...                                                    ...   \n",
       "1157634  Aholi zichligi – har kvadrat kilometrga 25,4 n...   \n",
       "1157635                         Shundan 3,70 km2 quruqlik.   \n",
       "1157636  Dengiz sathidan oʻrtacha 290 m balandlikda joy...   \n",
       "1157637                               Amenia, North Dakota   \n",
       "1157638                            Amenia, Shimoliy Dakota   \n",
       "\n",
       "                                                clean_text  \n",
       "0                           shoʻrvashoʻrva suyuq ovqat tur  \n",
       "1        tayyorlash usul koʻra shoʻrva qovurma shoʻrva ...  \n",
       "2        goʻsht boʻlak boʻlinib yogʻ qizarguncha soʻngr...  \n",
       "3        suv qaynab chiqquncha qozon tuz dona qizil qal...  \n",
       "4        shoʻrva qaynab chiqqach olov pasaytirilib soat...  \n",
       "...                                                    ...  \n",
       "1157634  ahol zichlig kvadrat kilometr kish geografiya ...  \n",
       "1157635                                      shun quruqlik  \n",
       "1157636              de sath oʻrtacha balandlik joylashgan  \n",
       "1157637                                amenia north dakota  \n",
       "1157638                             amenia shimoliy dakota  \n",
       "\n",
       "[1157639 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYYLljVTmbym"
   },
   "source": [
    "# Group data by page (pg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_page_ind = pd.DataFrame(dataframe['article_uuid'].unique(), columns=['article_uuid'])\n",
    "    df_page_ind = df_page_ind.reset_index().rename(columns={'index': 'pg_index'})\n",
    "    dataframe = dataframe.merge(df_page_ind, how='left', on='article_uuid')\n",
    "    dataframe = dataframe[['clean_text', 'pg_index']]\n",
    "    dataframe = dataframe.groupby(by='pg_index').agg({'clean_text': ' '.join})\n",
    "    df_pg = dataframe.reset_index()\n",
    "    df_pg = df_pg.dropna()\n",
    "    return df_pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_texts = group_texts(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pg_index</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>shoʻrvashoʻrva suyuq ovqat tur tayyorlash usul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sho rva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sho rva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sho'rva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>shoʻrkul suv omborishoʻrkul suv ombor buxoro v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440968</th>\n",
       "      <td>440968</td>\n",
       "      <td>ambrose north dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440969</th>\n",
       "      <td>440969</td>\n",
       "      <td>ambrose shimoliy dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440970</th>\n",
       "      <td>440970</td>\n",
       "      <td>amenia shimoliy dakota amenia aqsh shimoliy da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440971</th>\n",
       "      <td>440971</td>\n",
       "      <td>amenia north dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440972</th>\n",
       "      <td>440972</td>\n",
       "      <td>amenia shimoliy dakota</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440973 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pg_index                                         clean_text\n",
       "0              0  shoʻrvashoʻrva suyuq ovqat tur tayyorlash usul...\n",
       "1              1                                            sho rva\n",
       "2              2                                            sho rva\n",
       "3              3                                            sho'rva\n",
       "4              4  shoʻrkul suv omborishoʻrkul suv ombor buxoro v...\n",
       "...          ...                                                ...\n",
       "440968    440968                               ambrose north dakota\n",
       "440969    440969                            ambrose shimoliy dakota\n",
       "440970    440970  amenia shimoliy dakota amenia aqsh shimoliy da...\n",
       "440971    440971                                amenia north dakota\n",
       "440972    440972                             amenia shimoliy dakota\n",
       "\n",
       "[440973 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_textshape_data(dataframe: pd.DataFrame, text_shape: list, column: str) -> pd.DataFrame:\n",
    "    data_text_shape = pd.DataFrame(columns=['text_shape', 'pages_amount'])\n",
    "    for shape in text_shape:\n",
    "        lambda_ = lambda text: len(text.split()) > shape\n",
    "        pages_amount = dataframe[dataframe[column].apply(lambda_)].shape[0]\n",
    "        data_text_shape = data_text_shape.append({'text_shape': shape,\n",
    "                                                  'pages_amount': pages_amount}, ignore_index=True)\n",
    "    return data_text_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_shape</th>\n",
       "      <th>pages_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>16214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>9583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_shape pages_amount\n",
       "0        100        16214\n",
       "1        150         9583\n",
       "2        300         3495\n",
       "3        500         1577\n",
       "4       1000          581"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_textshape_data(df_grouped_texts, [100, 150, 300, 500, 1000], 'clean_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need to get a corpus of 10,000 documents, it is permissible that each document contains at least 150 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = lambda text: len(text.split()) > 150\n",
    "df_uz_corpus = df_grouped_texts[df_grouped_texts['clean_text'].apply(lambda_)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pg_index</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>shoʻrlanishshoʻrlanish tuproq shoʻrlanish suv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>shoʻro islomiya shoʻro islomiya islo kengash t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>shoʻrtan gaz-kimyo majmuasishoʻrtan gaz-kimyo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>shoʻrtoʻgʻoyshoʻrtoʻgʻoy shoʻrtoʻqay jez davr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>shoʻrxoklarshoʻrxok yuqor qatlam koʻproq suv o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9578</th>\n",
       "      <td>437284</td>\n",
       "      <td>437284</td>\n",
       "      <td>favvorafavvora biror manba suv biror jo tushib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9579</th>\n",
       "      <td>437305</td>\n",
       "      <td>437305</td>\n",
       "      <td>bj rkbj rk toʻliq is bj rk gu mundsd ttir tala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9580</th>\n",
       "      <td>437889</td>\n",
       "      <td>437889</td>\n",
       "      <td>maks gorkiy noml umumiy oʻrta maktab maks gork...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9581</th>\n",
       "      <td>439612</td>\n",
       "      <td>439612</td>\n",
       "      <td>bayanavul tuman bayanavul tuma pavlodar viloya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9582</th>\n",
       "      <td>439613</td>\n",
       "      <td>439613</td>\n",
       "      <td>viete formulalariviete formula koʻphad koeffit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9583 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  pg_index                                         clean_text\n",
       "0         20        20  shoʻrlanishshoʻrlanish tuproq shoʻrlanish suv ...\n",
       "1         62        62  shoʻro islomiya shoʻro islomiya islo kengash t...\n",
       "2        102       102  shoʻrtan gaz-kimyo majmuasishoʻrtan gaz-kimyo ...\n",
       "3        134       134  shoʻrtoʻgʻoyshoʻrtoʻgʻoy shoʻrtoʻqay jez davr ...\n",
       "4        142       142  shoʻrxoklarshoʻrxok yuqor qatlam koʻproq suv o...\n",
       "...      ...       ...                                                ...\n",
       "9578  437284    437284  favvorafavvora biror manba suv biror jo tushib...\n",
       "9579  437305    437305  bj rkbj rk toʻliq is bj rk gu mundsd ttir tala...\n",
       "9580  437889    437889  maks gorkiy noml umumiy oʻrta maktab maks gork...\n",
       "9581  439612    439612  bayanavul tuman bayanavul tuma pavlodar viloya...\n",
       "9582  439613    439613  viete formulalariviete formula koʻphad koeffit...\n",
       "\n",
       "[9583 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uz_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uz_corpus.to_csv(\"UzCleanCorpus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPP2anUoDkp0WgymSGEnT5a",
   "collapsed_sections": [
    "EvKLls3Ol-vr",
    "EYYLljVTmbym"
   ],
   "mount_file_id": "16k9tBMciW7usx9adm1fkWPtKUFoG-jcy",
   "name": "ReadWiki.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
